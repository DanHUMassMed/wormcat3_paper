{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eaf18803",
   "metadata": {},
   "source": [
    "## Environment\n",
    "Using Kernel: `dan-dev-py312-r433`\n",
    "\n",
    "-----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b17b1b",
   "metadata": {},
   "source": [
    "#### Stage the data\n",
    "\n",
    "- Staging Walker Lab Data from **source_data** to **derived_data**\n",
    "\n",
    "**Directories:**\n",
    "> - low_sam_s009\n",
    "> - low_sam_s012\n",
    "> - cut_and_tag\n",
    "> - wc1_random\n",
    "> - wc1_sams\n",
    "> - wc2_peptides\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0bb82efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Location of data from and to\n",
    "from pathlib import Path\n",
    "\n",
    "root_dir_path = Path(\"/Users/dan/Code/Python/wormcat3_paper\")\n",
    "excel_root_path = root_dir_path / \"source_data/walker_lab\"\n",
    "csv_root_path = root_dir_path / \"derived_data/walker_lab\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1adf9b6d",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8769c645",
   "metadata": {},
   "source": [
    "### Stage the original source data\n",
    "\n",
    "- Data is converted into a format that is easily consumed by Wormcat3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7edd80b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions used to Map Sequence IDs to Wormbase IDs\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from pub_worm.wormbase import wormbase_util as wb\n",
    "import os\n",
    "\n",
    "def get_gene_ids_dict(working_dir_path):\n",
    "    wormbase_version = wb.current_wormbase_version()\n",
    "    \n",
    "    gene_ids_csv = Path(f\"{working_dir_path}/c_elegans.PRJNA13758.{wormbase_version}.geneIDs.csv\")\n",
    "    if not gene_ids_csv.exists():        \n",
    "        gene_ids_txt = wb.download_gene_ids(wormbase_version, working_dir_path)\n",
    "        gene_ids_csv = wb.gene_ids_to_csv(wormbase_version, working_dir_path, status_live=False)\n",
    "        if os.path.exists(gene_ids_txt):\n",
    "            os.remove(gene_ids_txt)\n",
    "            \n",
    "    gene_ids_df = pd.read_csv(gene_ids_csv).fillna('')\n",
    "            \n",
    "    gene_ids_dict = {}\n",
    "    for _, row in gene_ids_df.iterrows():\n",
    "        for key in ['Wormbase_Id', 'Gene_name', 'Sequence_id']:\n",
    "            id_val = str(row[key]).upper()\n",
    "            gene_ids_dict[id_val] = row.to_dict()\n",
    "\n",
    "    return gene_ids_dict\n",
    "\n",
    "def lookup_wormbase_id(sequence_id, gene_ids_dict):\n",
    "    sequence_id = str(sequence_id)\n",
    "    found_wormbase_id = wb._lookup_wormbase_id(sequence_id, gene_ids_dict)\n",
    "    if found_wormbase_id is not None:\n",
    "        return found_wormbase_id['Wormbase_Id']\n",
    "    return None\n",
    "\n",
    "def read_csvs_to_dict(root_dir):\n",
    "    \"\"\"\n",
    "    Recursively find all CSV files in root_dir and read them into a dictionary of DataFrames.\n",
    "    The key is the relative path (as string) from root_dir.\n",
    "    \"\"\"\n",
    "    root_path = Path(root_dir)\n",
    "    csv_files = root_path.rglob('*.csv')\n",
    "    \n",
    "    dataframes = {}\n",
    "    for file_path in csv_files:\n",
    "        if file_path.name.endswith('.geneIDs.csv'):\n",
    "            continue  # skip this file\n",
    "        try:\n",
    "            relative_path = file_path.relative_to(root_path)\n",
    "            dataframes[str(relative_path)] = pd.read_csv(file_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to read {file_path}: {e}\")\n",
    "    \n",
    "    return dataframes\n",
    "\n",
    "def process_csvs(dest_dir):\n",
    "    csvs_dict = read_csvs_to_dict(dest_dir)\n",
    "    for file_path, df in csvs_dict.items():\n",
    "        output_file = dest_dir / file_path\n",
    "        df.insert(\n",
    "            0,  # position as the first column\n",
    "            'Wormbase_Id',\n",
    "            df['ID'].apply(lambda sequence_id: lookup_wormbase_id(sequence_id, gene_ids_dict))\n",
    "        )\n",
    "        \n",
    "        num_not_found = df['Wormbase_Id'].isna().sum()\n",
    "        total = len(df)\n",
    "        num_found = total - num_not_found\n",
    "        percent_found = num_found / total * 100\n",
    "        \n",
    "        print(output_file.name)\n",
    "        print(f\"Found     {num_found:>6,} genes.\")\n",
    "        print(f\"Not Found {num_not_found:>6,} genes.\")\n",
    "        print(f\"Processed {total:>6,} genes.  {percent_found:.2f}% matched.\")\n",
    "        print(\"=\"*40)\n",
    "        \n",
    "        df.to_csv(output_file, index=False)   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc824e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To map Sequence IDs to Wormbase IDs we build a gene ID dictionary for quick lookups\n",
    "import pandas as pd\n",
    "\n",
    "gene_ids_dict = get_gene_ids_dict(csv_root_path.parent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42a6d6df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sams-1_all.csv\n",
      "sams-1_up.csv\n",
      "sams-1_down.csv\n",
      "set-2_all.csv\n",
      "set-2_up.csv\n",
      "set-2_down.csv\n",
      "set-16_all.csv\n",
      "set-16_up.csv\n",
      "set-16_down.csv\n",
      "set-16_all.csv\n",
      "Found     16,581 genes.\n",
      "Not Found    125 genes.\n",
      "Processed 16,706 genes.  99.25% matched.\n",
      "========================================\n",
      "set-2_all.csv\n",
      "Found     16,513 genes.\n",
      "Not Found    128 genes.\n",
      "Processed 16,641 genes.  99.23% matched.\n",
      "========================================\n",
      "sams-1_all.csv\n",
      "Found     17,729 genes.\n",
      "Not Found    139 genes.\n",
      "Processed 17,868 genes.  99.22% matched.\n",
      "========================================\n",
      "set-2_up.csv\n",
      "Found          1 genes.\n",
      "Not Found      0 genes.\n",
      "Processed      1 genes.  100.00% matched.\n",
      "========================================\n",
      "set-2_down.csv\n",
      "Found          0 genes.\n",
      "Not Found      2 genes.\n",
      "Processed      2 genes.  0.00% matched.\n",
      "========================================\n",
      "sams-1_down.csv\n",
      "Found      2,316 genes.\n",
      "Not Found      5 genes.\n",
      "Processed  2,321 genes.  99.78% matched.\n",
      "========================================\n",
      "sams-1_up.csv\n",
      "Found      1,198 genes.\n",
      "Not Found      5 genes.\n",
      "Processed  1,203 genes.  99.58% matched.\n",
      "========================================\n",
      "set-16_up.csv\n",
      "Found         30 genes.\n",
      "Not Found      0 genes.\n",
      "Processed     30 genes.  100.00% matched.\n",
      "========================================\n",
      "set-16_down.csv\n",
      "Found         49 genes.\n",
      "Not Found      0 genes.\n",
      "Processed     49 genes.  100.00% matched.\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "excel_file = excel_root_path / \"low_sam\" / \"pgen.1007812.s009.xlsx\"\n",
    "dest_dir   = csv_root_path / \"low_sam_s009\"\n",
    "\n",
    "sheet_map = {\n",
    "    'sams-1 ALL genes': 'all_detected/sams-1_all.csv',\n",
    "    'sams-1 UP': 'sams-1/sams-1_up.csv',\n",
    "    'sams-1 DOWN': 'sams-1/sams-1_down.csv',\n",
    "    'set-2 ALL': 'all_detected/set-2_all.csv',\n",
    "    'set-2 UP': 'set-2/set-2_up.csv',\n",
    "    'set-2 DOWN': 'set-2/set-2_down.csv',\n",
    "    'set-16 ALL': 'all_detected/set-16_all.csv',\n",
    "    'set-16 UP': 'set-16/set-16_up.csv',\n",
    "    'set-16 DOWN': 'set-16/set-16_down.csv'\n",
    "}\n",
    "        \n",
    "input_excel = pd.ExcelFile(excel_file)\n",
    "for sheet in input_excel.sheet_names:\n",
    "    sheet_df = input_excel.parse(sheet)\n",
    "    output_file = dest_dir / sheet_map[sheet]\n",
    "    print(output_file.name)\n",
    "    output_file.parent.mkdir(parents=True, exist_ok=True)\n",
    "    sheet_df.to_csv(output_file, index=False)            \n",
    "\n",
    "            \n",
    "process_csvs(dest_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9edeaca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "control_up.csv\n",
      "sams-1_up.csv\n",
      "set-2_up.csv\n",
      "set-16_up.csv\n",
      "control_down.csv\n",
      "sams-1_down.csv\n",
      "set-2_down.csv\n",
      "set-16_down.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "excel_file = excel_root_path / \"low_sam\" / \"pgen.1007812.s012.xlsx\"\n",
    "dest_dir   = csv_root_path / \"low_sam_s012\"\n",
    "\n",
    "sheet_map = {\n",
    "    'control UP Heat'  :'control/control_up.csv',\n",
    "    'control DOWN Heat':'control/control_down.csv',\n",
    "    'sams UP Heat'     :'sams-1/sams-1_up.csv',\n",
    "    'sams DOWN Heat'   :'sams-1/sams-1_down.csv',\n",
    "    'set2 UP Heat'     :'set-2/set-2_up.csv',\n",
    "    'set2 DOWN Heat'   :'set-2/set-2_down.csv',\n",
    "    'set16 UP Heat'    :'set-16/set-16_up.csv',\n",
    "    'set16 DOWN Heat'  :'set-16/set-16_down.csv'\n",
    "}\n",
    "        \n",
    "input_excel = pd.ExcelFile(excel_file)\n",
    "for sheet in input_excel.sheet_names:\n",
    "    sheet_df = input_excel.parse(sheet)\n",
    "    sheet_df = sheet_df.rename(columns={'wormbase_id': 'Wormbase_Id'})\n",
    "    output_file = dest_dir / sheet_map[sheet]\n",
    "    print(output_file.name)\n",
    "    output_file.parent.mkdir(parents=True, exist_ok=True)\n",
    "    sheet_df.to_csv(output_file, index=False)            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52feae78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Legend\n",
      "A. Control_15\n",
      "B. Control_37\n",
      "C. S1_15\n",
      "D. S1_37\n",
      "E. S4_15\n",
      "F. S4_37\n",
      "G. Cat1\n",
      "H. Cat2\n",
      "I. Cat3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "excel_file = excel_root_path / \"cut_and_tag\" / \"elife-79511-supp3-v3.xlsx\"\n",
    "dest_dir   = csv_root_path / \"cut_and_tag\"\n",
    "\n",
    "sheet_map = {\n",
    "    'Legend'        :'cut_and_tag_results/legend.csv',\n",
    "    'A. Control_15' :'control/control_15.csv',\n",
    "    'B. Control_37' :'control/control_37.csv',\n",
    "    'C. S1_15'      :'sams-1/sams-1_15.csv',\n",
    "    'D. S1_37'      :'sams-1/sams-1_37.csv',\n",
    "    'E. S4_15'      :'sams-4/sams-4_15.csv',\n",
    "    'F. S4_37'      :'sams-4/sams-4_37.csv',\n",
    "    'G. Cat1'       :'cut_and_tag_results/cat1.csv',\n",
    "    'H. Cat2'       :'cut_and_tag_results/cat2.csv',\n",
    "    'I. Cat3'       :'cut_and_tag_results/cat3.csv'\n",
    "}\n",
    "        \n",
    "input_excel = pd.ExcelFile(excel_file)\n",
    "for sheet in input_excel.sheet_names:\n",
    "    sheet_df = input_excel.parse(sheet)\n",
    "    print(sheet)\n",
    "    if 'Unnamed: 0'in sheet_df.columns:\n",
    "        sheet_df = sheet_df.drop(columns='Unnamed: 0')\n",
    "    if 'Wormbase_ID' in sheet_df.columns:\n",
    "        # Rename the column\n",
    "        sheet_df = sheet_df.rename(columns={'Wormbase_ID': 'Wormbase_Id'})\n",
    "        # Move 'Wormbase_Id' to the first column\n",
    "        cols = ['Wormbase_Id'] + [col for col in sheet_df.columns if col != 'Wormbase_Id']\n",
    "        sheet_df = sheet_df[cols]\n",
    "    output_file = dest_dir / sheet_map[sheet]\n",
    "    output_file.parent.mkdir(parents=True, exist_ok=True)\n",
    "    sheet_df.to_csv(output_file, index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "938b27ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table S3 Legend\n",
      "1 Random_100_genes\n",
      "2 Random_100_cat1\n",
      "3 Random_100_cat2\n",
      "4 Random_100_cat3\n",
      "5 Random_500_genes\n",
      "6 Random_500_cat1\n",
      "7 Random_500_cat2\n",
      "8 Random_500_cat3\n",
      "9 Random_1000_genes\n",
      "10 Random_1000_cat1\n",
      "11 Random_1000_cat2\n",
      "12 Random_1000_cat3\n",
      "13 Random_1500_genes\n",
      "14 Random_1500_cat1\n",
      "15 Random_1500_cat2\n",
      "16 Random_1500_cat3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "excel_file = excel_root_path / \"wormcat_1\" / \"Supplemental_Table_3.xlsx\"\n",
    "dest_dir   = csv_root_path / \"wc1_random\"\n",
    "\n",
    "sheet_map = {\n",
    "\t'Table S3 Legend'      :'wormcat1_results/legend.csv',\n",
    "\t'1 Random_100_genes'   :'random/random_100.csv',\n",
    "\t'2 Random_100_cat1'    :'wormcat1_results/random_100_cat1.csv',\n",
    "\t'3 Random_100_cat2'    :'wormcat1_results/random_100_cat2.csv',\n",
    "\t'4 Random_100_cat3'    :'wormcat1_results/random_100_cat3.csv',\n",
    "\t'5 Random_500_genes'   :'random/random_500.csv',\n",
    "\t'6 Random_500_cat1'    :'wormcat1_results/random_500_cat1.csv',\n",
    "\t'7 Random_500_cat2'    :'wormcat1_results/random_500_cat2.csv',\n",
    "\t'8 Random_500_cat3'    :'wormcat1_results/random_500_cat3.csv',\n",
    "\t'9 Random_1000_genes'  :'random/random_1000.csv',\n",
    "\t'10 Random_1000_cat1'  :'wormcat1_results/random_1000_cat1.csv',\n",
    "\t'11 Random_1000_cat2'  :'wormcat1_results/random_1000_cat2.csv',\n",
    "\t'12 Random_1000_cat3'  :'wormcat1_results/random_1000_cat3.csv',\n",
    "\t'13 Random_1500_genes' :'random/random_1500.csv',\n",
    "\t'14 Random_1500_cat1'  :'wormcat1_results/random_1500_cat1.csv',\n",
    "\t'15 Random_1500_cat2'  :'wormcat1_results/random_1500_cat2.csv',\n",
    "\t'16 Random_1500_cat3'  :'wormcat1_results/random_1500_cat3.csv'\n",
    "}\n",
    "        \n",
    "input_excel = pd.ExcelFile(excel_file)\n",
    "for sheet in input_excel.sheet_names:\n",
    "    sheet_df = input_excel.parse(sheet)\n",
    "    print(sheet)\n",
    "    if 'Unnamed: 0'in sheet_df.columns:\n",
    "        sheet_df = sheet_df.drop(columns='Unnamed: 0')\n",
    "    if 'Wormbase.ID' in sheet_df.columns:\n",
    "        # Rename the column\n",
    "        sheet_df = sheet_df.rename(columns={'Wormbase.ID': 'Wormbase_Id'})\n",
    "        cols = ['Wormbase_Id'] + [col for col in sheet_df.columns if col != 'Wormbase_Id']\n",
    "        sheet_df = sheet_df[cols]\n",
    "    output_file = dest_dir / sheet_map[sheet]\n",
    "    output_file.parent.mkdir(parents=True, exist_ok=True)\n",
    "    sheet_df.to_csv(output_file, index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46262006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table S5 Legend\n",
      "1 Cat1\n",
      "2 Cat2\n",
      "3 Cat3\n",
      "4 sams_up_genes\n",
      "5 sams_down_genes\n",
      "6 sams_up_CH_genes\n",
      "7 sams_down_CH_genes\n"
     ]
    }
   ],
   "source": [
    "# Process Supplemental_Table_5 Data of Wormcat Paper 1\n",
    "\n",
    "excel_file = excel_root_path / \"wormcat_1\" / \"Supplemental_Table_5.xlsx\"\n",
    "dest_dir   = csv_root_path / \"wc1_sams\"\n",
    "\n",
    "sheet_map = {\n",
    "\t'Table S5 Legend'      :'wormcat1_results/legend.csv',\n",
    "\t'1 Cat1'               :'wormcat1_results/cat1.csv',\n",
    "\t'2 Cat2'               :'wormcat1_results/cat2.csv',\n",
    "\t'3 Cat3'               :'wormcat1_results/cat3.csv',\n",
    "\t'4 sams_up_genes'      :'sams/sams_up.csv',\n",
    "\t'5 sams_down_genes'    :'sams/sams_down.csv',\n",
    "\t'6 sams_up_CH_genes'   :'sams/sams_up_ch.csv',\n",
    "\t'7 sams_down_CH_genes' :'sams/sams_down_ch.csv'\n",
    "}\n",
    "\n",
    "input_excel = pd.ExcelFile(excel_file)\n",
    "for sheet in input_excel.sheet_names:\n",
    "    sheet_df = input_excel.parse(sheet)\n",
    "    print(sheet)\n",
    "    if 'Unnamed: 0'in sheet_df.columns:\n",
    "        sheet_df = sheet_df.drop(columns='Unnamed: 0')\n",
    "    if 'Wormbase.ID' in sheet_df.columns:\n",
    "        # Rename the column\n",
    "        sheet_df = sheet_df.rename(columns={'Wormbase.ID': 'Wormbase_Id'})\n",
    "        cols = ['Wormbase_Id'] + [col for col in sheet_df.columns if col != 'Wormbase_Id']\n",
    "        sheet_df = sheet_df[cols]\n",
    "    output_file = dest_dir / sheet_map[sheet]\n",
    "    output_file.parent.mkdir(parents=True, exist_ok=True)\n",
    "    sheet_df.to_csv(output_file, index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e01b3093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Legend\n",
      "1. Cat1\n",
      "2. Cat2\n",
      "3. Cat3\n",
      "4. all_detected_peptides_cat\n",
      "5. aging.change_cat\n",
      "6. Cytoplasm_cat\n"
     ]
    }
   ],
   "source": [
    "# Group Supplemental_Table_S8 Data into Subdirectories for Wormcat Batch Execution\n",
    "\n",
    "excel_file = excel_root_path / \"wormcat_2\" / \"Table S8.xlsx\"\n",
    "dest_dir   = csv_root_path / \"wc2_peptides\"\n",
    "\n",
    "sheet_map = {\n",
    "\t'Legend'                       :'wormcat2_results/legend.csv',\n",
    "\t'1. Cat1'                      :'wormcat2_results/cat1.csv',\n",
    "\t'2. Cat2'                      :'wormcat2_results/cat2.csv',\n",
    "\t'3. Cat3'                      :'wormcat2_results/cat3.csv',\n",
    "\t'4. all_detected_peptides_cat' :'peptides/all_detected_peptides.csv',\n",
    "\t'5. aging.change_cat'          :'peptides/aging_change.csv',\n",
    "\t'6. Cytoplasm_cat'             :'peptides/cytoplasm.csv'\n",
    "}\n",
    "\n",
    "input_excel = pd.ExcelFile(excel_file)\n",
    "for sheet in input_excel.sheet_names:\n",
    "    sheet_df = input_excel.parse(sheet)\n",
    "    print(sheet)\n",
    "    if 'Unnamed: 0'in sheet_df.columns:\n",
    "        sheet_df = sheet_df.drop(columns='Unnamed: 0')\n",
    "    if 'Wormbase.ID' in sheet_df.columns:\n",
    "        # Rename the column\n",
    "        sheet_df = sheet_df.rename(columns={'Wormbase.ID': 'Wormbase_Id'})\n",
    "        cols = ['Wormbase_Id'] + [col for col in sheet_df.columns if col != 'Wormbase_Id']\n",
    "        sheet_df = sheet_df[cols]\n",
    "    output_file = dest_dir / sheet_map[sheet]\n",
    "    output_file.parent.mkdir(parents=True, exist_ok=True)\n",
    "    sheet_df.to_csv(output_file, index=False) \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2bcd82e",
   "metadata": {},
   "source": [
    "# Basement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b39bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Helper functions to stage the original source data \n",
    "# import glob\n",
    "# import os\n",
    "# import re\n",
    "# import pandas as pd\n",
    "# import shutil\n",
    "# from pathlib import Path\n",
    "# from wormcat3.wormcat_excel import WormcatExcel\n",
    "\n",
    "\n",
    "# def delete_directory_recursive(csv_root_path):\n",
    "#     \"\"\"Delete the content of the provided directory and all subdirectories.\"\"\"\n",
    "#     path = Path(csv_root_path)\n",
    "#     if path.exists() and path.is_dir():\n",
    "#         shutil.rmtree(path)\n",
    "#         print(f\"Deleted directory and all contents: {csv_root_path}\")\n",
    "#     else:\n",
    "#         print(f\"Directory does not exist: {csv_root_path}\")\n",
    "        \n",
    "\n",
    "# def rename_file(file_path: Path, new_name: str) -> Path:\n",
    "#     \"\"\"Rename the file at file_path to the new_name in the same directory, and return the new path.\"\"\"\n",
    "#     if not file_path.exists():\n",
    "#         new_path = file_path.with_name(new_name)\n",
    "#         return new_path # Assume it was already moved\n",
    "#         #raise FileNotFoundError(f\"File does not exist: {file_path}\")\n",
    "\n",
    "#     new_path = file_path.with_name(new_name)\n",
    "#     try:\n",
    "#         file_path.rename(new_path)\n",
    "#         print(f\"Renamed: {file_path.name} → {new_name}\")\n",
    "#         return new_path\n",
    "#     except Exception as e:\n",
    "#         print(f\"Failed to rename {file_path}: {e}\")\n",
    "#         return file_path  # fallback\n",
    "    \n",
    "            \n",
    "# def move_filtered_files(pattern, destination, regex_pattern=None):\n",
    "#     \"\"\"\n",
    "#     Move files matching a glob pattern and optional apply a regex filter to the destination folder.\n",
    "#     \"\"\"\n",
    "#     pattern = str(pattern)\n",
    "#     destination = str(destination)\n",
    "#     os.makedirs(destination, exist_ok=True)\n",
    "#     files = glob.glob(pattern)\n",
    "\n",
    "#     if regex_pattern:\n",
    "#         regex = re.compile(regex_pattern)\n",
    "#         files = [f for f in files if regex.match(os.path.basename(f))]\n",
    "\n",
    "#     for file in files:\n",
    "#         try:\n",
    "#             dest_path = os.path.join(destination, os.path.basename(file))\n",
    "#             if os.path.exists(dest_path):\n",
    "#                 os.remove(dest_path)  # Remove existing file to allow overwriting\n",
    "#             shutil.move(file, dest_path)\n",
    "#         except Exception as e:\n",
    "#             print(f\"Failed to move {file}: {e}\")\n",
    "            \n",
    "\n",
    "# def extract_all_excels_to_csv(excel_dir: Path, csv_root_dir: Path):\n",
    "#     \"\"\"\n",
    "#     Read all .xlsx files from excel_dir and extract their sheets as CSVs into\n",
    "#     separate subdirectories under csv_root_dir named after each Excel file stem.\n",
    "#     \"\"\"\n",
    "#     excel_dir = Path(excel_dir)\n",
    "#     csv_root_dir = Path(csv_root_dir)\n",
    "#     csv_root_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "#     for excel_file in excel_dir.iterdir():\n",
    "#         if excel_file.suffix.lower() != \".xlsx\":\n",
    "#             continue\n",
    "        \n",
    "#         print(f\"Extracting {excel_file.name}…\")\n",
    "#         dest_dir = csv_root_dir / excel_file.stem\n",
    "#         dest_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "#         WormcatExcel.extract_csv_files(excel_file, dest_dir)\n",
    "        \n",
    "# def remove_index_column(directory):\n",
    "#     for csv_file in directory.rglob(\"*.csv\"):\n",
    "#         df = pd.read_csv(csv_file)\n",
    "        \n",
    "#         # Check if the first column is 'Unnamed: 0'\n",
    "#         if df.columns[0] == 'Unnamed: 0':\n",
    "#             df = df.drop(columns='Unnamed: 0')\n",
    "#             df.to_csv(csv_file, index=False)\n",
    "#             print(f\"Cleaned and saved: {csv_file.name}\")\n",
    "#         else:\n",
    "#             print(f\"No change needed: {csv_file.name}\")\n",
    "            \n",
    "# def remove_prefix_and_rename_csvs(directory, pattern=r\"^\\d{1,2} (.+)\"):\n",
    "#     \"\"\"\n",
    "#     Recursively rename CSV files in a directory by removing a prefix\n",
    "#     matched by the given regex pattern from the filename.\n",
    "    \n",
    "#     By default, removes a leading number and space (e.g., '01 filename.csv' → 'filename.csv').\n",
    "#     \"\"\"\n",
    "#     directory = Path(directory)\n",
    "#     regex = re.compile(pattern)\n",
    "\n",
    "#     for file in directory.rglob(\"*.csv\"):\n",
    "#         match = regex.match(file.name)\n",
    "#         if match:\n",
    "#             new_name = match.group(1)\n",
    "#             new_path = file.with_name(new_name)\n",
    "#             try:\n",
    "#                 file.rename(new_path)\n",
    "#                 print(f\"Renamed: {file.relative_to(directory)} → {new_name}\")\n",
    "#             except Exception as e:\n",
    "#                 print(f\"Failed to rename {file}: {e}\")\n",
    "                "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dan-dev-py312-r433",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
