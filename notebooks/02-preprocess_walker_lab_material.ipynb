{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eaf18803",
   "metadata": {},
   "source": [
    "## Environment\n",
    "Using Kernel: `dan-dev-py312-r433`\n",
    "\n",
    "-----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a7288b",
   "metadata": {},
   "source": [
    "# Walker Lab Preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b17b1b",
   "metadata": {},
   "source": [
    "#### Stage the data\n",
    "\n",
    "- Staging Data from **source_data** to **derived_data**\n",
    "\n",
    "**Derived Directories:**\n",
    "> - low_sam_s009\n",
    "> - low_sam_s012\n",
    "> - cut_and_tag\n",
    "> - wc1_random\n",
    "> - wc1_sams\n",
    "> - wc2_peptides\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8769c645",
   "metadata": {},
   "source": [
    "-----\n",
    "- **Helper functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7edd80b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions used to Map Sequence IDs to Wormbase IDs\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from pub_worm.wormbase import wormbase_util as wb\n",
    "import os\n",
    "\n",
    "def get_gene_ids_dict(working_dir_path):\n",
    "    wormbase_version = wb.current_wormbase_version()\n",
    "    \n",
    "    gene_ids_csv = Path(f\"{working_dir_path}/c_elegans.PRJNA13758.{wormbase_version}.geneIDs.csv\")\n",
    "    if not gene_ids_csv.exists():        \n",
    "        gene_ids_txt = wb.download_gene_ids(wormbase_version, working_dir_path)\n",
    "        gene_ids_csv = wb.gene_ids_to_csv(wormbase_version, working_dir_path, status_live=False)\n",
    "        if os.path.exists(gene_ids_txt):\n",
    "            os.remove(gene_ids_txt)\n",
    "            \n",
    "    gene_ids_df = pd.read_csv(gene_ids_csv).fillna('')\n",
    "            \n",
    "    gene_ids_dict = {}\n",
    "    for _, row in gene_ids_df.iterrows():\n",
    "        for key in ['Wormbase_Id', 'Gene_name', 'Sequence_id']:\n",
    "            id_val = str(row[key]).upper()\n",
    "            gene_ids_dict[id_val] = row.to_dict()\n",
    "\n",
    "    return gene_ids_dict\n",
    "\n",
    "def lookup_wormbase_id(sequence_id, gene_ids_dict):\n",
    "    sequence_id = str(sequence_id)\n",
    "    found_wormbase_id = wb._lookup_wormbase_id(sequence_id, gene_ids_dict)\n",
    "    if found_wormbase_id is not None:\n",
    "        return found_wormbase_id['Wormbase_Id']\n",
    "    return None\n",
    "\n",
    "def read_csvs_to_dict(root_dir):\n",
    "    \"\"\"\n",
    "    Recursively find all CSV files in root_dir and read them into a dictionary of DataFrames.\n",
    "    The key is the relative path (as string) from root_dir.\n",
    "    \"\"\"\n",
    "    root_path = Path(root_dir)\n",
    "    csv_files = root_path.rglob('*.csv')\n",
    "    \n",
    "    dataframes = {}\n",
    "    for file_path in csv_files:\n",
    "        if file_path.name.endswith('.geneIDs.csv'):\n",
    "            continue  # skip this file\n",
    "        try:\n",
    "            relative_path = file_path.relative_to(root_path)\n",
    "            dataframes[str(relative_path)] = pd.read_csv(file_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to read {file_path}: {e}\")\n",
    "    \n",
    "    return dataframes\n",
    "\n",
    "def process_csvs(dest_dir):\n",
    "    csvs_dict = read_csvs_to_dict(dest_dir)\n",
    "    for file_path, df in csvs_dict.items():\n",
    "        output_file = dest_dir / file_path\n",
    "        df.insert(\n",
    "            0,  # position as the first column\n",
    "            'Wormbase_Id',\n",
    "            df['ID'].apply(lambda sequence_id: lookup_wormbase_id(sequence_id, gene_ids_dict))\n",
    "        )\n",
    "        \n",
    "        num_not_found = df['Wormbase_Id'].isna().sum()\n",
    "        total = len(df)\n",
    "        num_found = total - num_not_found\n",
    "        percent_found = num_found / total * 100\n",
    "        \n",
    "        print(output_file.name)\n",
    "        print(f\"Found     {num_found:>6,} genes.\")\n",
    "        print(f\"Not Found {num_not_found:>6,} genes.\")\n",
    "        print(f\"Processed {total:>6,} genes.  {percent_found:.2f}% matched.\")\n",
    "        print(\"=\"*40)\n",
    "        \n",
    "        df.to_csv(output_file, index=False)   \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf95f67",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "- **Preprocess**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0bb82efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Location of data from and to\n",
    "from pathlib import Path\n",
    "\n",
    "source_data_path = Path(\"../source_data/walker_lab\")\n",
    "derived_data_path = Path(\"../derived_data/walker_lab\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc824e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To map Sequence IDs to Wormbase IDs we build a gene ID dictionary for quick lookups\n",
    "import pandas as pd\n",
    "\n",
    "gene_ids_dict = get_gene_ids_dict(derived_data_path.parent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42a6d6df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sams-1_all.csv\n",
      "sams-1_up.csv\n",
      "sams-1_down.csv\n",
      "set-2_all.csv\n",
      "set-2_up.csv\n",
      "set-2_down.csv\n",
      "set-16_all.csv\n",
      "set-16_up.csv\n",
      "set-16_down.csv\n",
      "set-16_all.csv\n",
      "Found     16,581 genes.\n",
      "Not Found    125 genes.\n",
      "Processed 16,706 genes.  99.25% matched.\n",
      "========================================\n",
      "set-2_all.csv\n",
      "Found     16,513 genes.\n",
      "Not Found    128 genes.\n",
      "Processed 16,641 genes.  99.23% matched.\n",
      "========================================\n",
      "sams-1_all.csv\n",
      "Found     17,729 genes.\n",
      "Not Found    139 genes.\n",
      "Processed 17,868 genes.  99.22% matched.\n",
      "========================================\n",
      "sams-1_down.csv\n",
      "Found      2,316 genes.\n",
      "Not Found      5 genes.\n",
      "Processed  2,321 genes.  99.78% matched.\n",
      "========================================\n",
      "set-2_up.csv\n",
      "Found          1 genes.\n",
      "Not Found      0 genes.\n",
      "Processed      1 genes.  100.00% matched.\n",
      "========================================\n",
      "set-16_up.csv\n",
      "Found         30 genes.\n",
      "Not Found      0 genes.\n",
      "Processed     30 genes.  100.00% matched.\n",
      "========================================\n",
      "sams-1_up.csv\n",
      "Found      1,198 genes.\n",
      "Not Found      5 genes.\n",
      "Processed  1,203 genes.  99.58% matched.\n",
      "========================================\n",
      "set-2_down.csv\n",
      "Found          0 genes.\n",
      "Not Found      2 genes.\n",
      "Processed      2 genes.  0.00% matched.\n",
      "========================================\n",
      "set-16_down.csv\n",
      "Found         49 genes.\n",
      "Not Found      0 genes.\n",
      "Processed     49 genes.  100.00% matched.\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "excel_file = source_data_path / \"low_sam\" / \"pgen.1007812.s009.xlsx\"\n",
    "dest_dir   = derived_data_path / \"low_sam_s009\"\n",
    "\n",
    "sheet_map = {\n",
    "    'sams-1 ALL genes': 'all_detected/sams-1_all.csv',\n",
    "    'sams-1 UP': 'basal_conditions/sams-1_up.csv',\n",
    "    'sams-1 DOWN': 'basal_conditions/sams-1_down.csv',\n",
    "    'set-2 ALL': 'all_detected/set-2_all.csv',\n",
    "    'set-2 UP': 'basal_conditions/set-2_up.csv',\n",
    "    'set-2 DOWN': 'basal_conditions/set-2_down.csv',\n",
    "    'set-16 ALL': 'all_detected/set-16_all.csv',\n",
    "    'set-16 UP': 'basal_conditions/set-16_up.csv',\n",
    "    'set-16 DOWN': 'basal_conditions/set-16_down.csv'\n",
    "}\n",
    "        \n",
    "input_excel = pd.ExcelFile(excel_file)\n",
    "for sheet in input_excel.sheet_names:\n",
    "    sheet_df = input_excel.parse(sheet)\n",
    "    output_file = dest_dir / sheet_map[sheet]\n",
    "    print(output_file.name)\n",
    "    output_file.parent.mkdir(parents=True, exist_ok=True)\n",
    "    sheet_df.to_csv(output_file, index=False)            \n",
    "\n",
    "            \n",
    "process_csvs(dest_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9edeaca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "control_up.csv\n",
      "sams-1_up.csv\n",
      "set-2_up.csv\n",
      "set-16_up.csv\n",
      "control_down.csv\n",
      "sams-1_down.csv\n",
      "set-2_down.csv\n",
      "set-16_down.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "excel_file = source_data_path / \"low_sam\" / \"pgen.1007812.s012.xlsx\"\n",
    "dest_dir   = derived_data_path / \"low_sam_s012\"\n",
    "\n",
    "sheet_map = {\n",
    "    'control UP Heat'  :'heat_shock/control_up.csv',\n",
    "    'control DOWN Heat':'heat_shock/control_down.csv',\n",
    "    'sams UP Heat'     :'heat_shock/sams-1_up.csv',\n",
    "    'sams DOWN Heat'   :'heat_shock/sams-1_down.csv',\n",
    "    'set2 UP Heat'     :'heat_shock/set-2_up.csv',\n",
    "    'set2 DOWN Heat'   :'heat_shock/set-2_down.csv',\n",
    "    'set16 UP Heat'    :'heat_shock/set-16_up.csv',\n",
    "    'set16 DOWN Heat'  :'heat_shock/set-16_down.csv'\n",
    "}\n",
    "        \n",
    "input_excel = pd.ExcelFile(excel_file)\n",
    "for sheet in input_excel.sheet_names:\n",
    "    sheet_df = input_excel.parse(sheet)\n",
    "    sheet_df = sheet_df.rename(columns={'wormbase_id': 'Wormbase_Id'})\n",
    "    output_file = dest_dir / sheet_map[sheet]\n",
    "    print(output_file.name)\n",
    "    output_file.parent.mkdir(parents=True, exist_ok=True)\n",
    "    sheet_df.to_csv(output_file, index=False)            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52feae78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Legend\n",
      "A. Control_15\n",
      "B. Control_37\n",
      "C. S1_15\n",
      "D. S1_37\n",
      "E. S4_15\n",
      "F. S4_37\n",
      "G. Cat1\n",
      "H. Cat2\n",
      "I. Cat3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "excel_file = source_data_path / \"cut_and_tag\" / \"elife-79511-supp3-v3.xlsx\"\n",
    "dest_dir   = derived_data_path / \"cut_and_tag\"\n",
    "\n",
    "sheet_map = {\n",
    "    'Legend'        :'cut_and_tag_results/legend.csv',\n",
    "    'A. Control_15' :'cut_and_tag/control_15.csv',\n",
    "    'B. Control_37' :'cut_and_tag/control_37.csv',\n",
    "    'C. S1_15'      :'cut_and_tag/sams-1_15.csv',\n",
    "    'D. S1_37'      :'cut_and_tag/sams-1_37.csv',\n",
    "    'E. S4_15'      :'cut_and_tag/sams-4_15.csv',\n",
    "    'F. S4_37'      :'cut_and_tag/sams-4_37.csv',\n",
    "    'G. Cat1'       :'cut_and_tag_results/cat1.csv',\n",
    "    'H. Cat2'       :'cut_and_tag_results/cat2.csv',\n",
    "    'I. Cat3'       :'cut_and_tag_results/cat3.csv'\n",
    "}\n",
    "        \n",
    "input_excel = pd.ExcelFile(excel_file)\n",
    "for sheet in input_excel.sheet_names:\n",
    "    sheet_df = input_excel.parse(sheet)\n",
    "    print(sheet)\n",
    "    if 'Unnamed: 0'in sheet_df.columns:\n",
    "        sheet_df = sheet_df.drop(columns='Unnamed: 0')\n",
    "        \n",
    "    sheet_df.columns = [col.strip().replace(' ', '_') for col in sheet_df.columns]\n",
    "    if 'Wormbase_ID' in sheet_df.columns:\n",
    "        # Rename the column\n",
    "        sheet_df = sheet_df.rename(columns={'Wormbase_ID': 'Wormbase_Id'})\n",
    "        # Move 'Wormbase_Id' to the first column\n",
    "        cols = ['Wormbase_Id'] + [col for col in sheet_df.columns if col != 'Wormbase_Id']\n",
    "        sheet_df = sheet_df[cols]\n",
    "    output_file = dest_dir / sheet_map[sheet]\n",
    "    output_file.parent.mkdir(parents=True, exist_ok=True)\n",
    "    sheet_df.to_csv(output_file, index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "938b27ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table S3 Legend\n",
      "1 Random_100_genes\n",
      "2 Random_100_cat1\n",
      "3 Random_100_cat2\n",
      "4 Random_100_cat3\n",
      "5 Random_500_genes\n",
      "6 Random_500_cat1\n",
      "7 Random_500_cat2\n",
      "8 Random_500_cat3\n",
      "9 Random_1000_genes\n",
      "10 Random_1000_cat1\n",
      "11 Random_1000_cat2\n",
      "12 Random_1000_cat3\n",
      "13 Random_1500_genes\n",
      "14 Random_1500_cat1\n",
      "15 Random_1500_cat2\n",
      "16 Random_1500_cat3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "excel_file = source_data_path / \"wormcat_1\" / \"Supplemental_Table_3.xlsx\"\n",
    "dest_dir   = derived_data_path / \"wc1_random\"\n",
    "\n",
    "sheet_map = {\n",
    "\t'Table S3 Legend'      :'wormcat1_results/legend.csv',\n",
    "\t'1 Random_100_genes'   :'random/random_100.csv',\n",
    "\t'2 Random_100_cat1'    :'wormcat1_results/random_100_cat1.csv',\n",
    "\t'3 Random_100_cat2'    :'wormcat1_results/random_100_cat2.csv',\n",
    "\t'4 Random_100_cat3'    :'wormcat1_results/random_100_cat3.csv',\n",
    "\t'5 Random_500_genes'   :'random/random_500.csv',\n",
    "\t'6 Random_500_cat1'    :'wormcat1_results/random_500_cat1.csv',\n",
    "\t'7 Random_500_cat2'    :'wormcat1_results/random_500_cat2.csv',\n",
    "\t'8 Random_500_cat3'    :'wormcat1_results/random_500_cat3.csv',\n",
    "\t'9 Random_1000_genes'  :'random/random_1000.csv',\n",
    "\t'10 Random_1000_cat1'  :'wormcat1_results/random_1000_cat1.csv',\n",
    "\t'11 Random_1000_cat2'  :'wormcat1_results/random_1000_cat2.csv',\n",
    "\t'12 Random_1000_cat3'  :'wormcat1_results/random_1000_cat3.csv',\n",
    "\t'13 Random_1500_genes' :'random/random_1500.csv',\n",
    "\t'14 Random_1500_cat1'  :'wormcat1_results/random_1500_cat1.csv',\n",
    "\t'15 Random_1500_cat2'  :'wormcat1_results/random_1500_cat2.csv',\n",
    "\t'16 Random_1500_cat3'  :'wormcat1_results/random_1500_cat3.csv'\n",
    "}\n",
    "        \n",
    "input_excel = pd.ExcelFile(excel_file)\n",
    "for sheet in input_excel.sheet_names:\n",
    "    sheet_df = input_excel.parse(sheet)\n",
    "    print(sheet)\n",
    "    if 'Unnamed: 0'in sheet_df.columns:\n",
    "        sheet_df = sheet_df.drop(columns='Unnamed: 0')\n",
    "    if 'Wormbase.ID' in sheet_df.columns:\n",
    "        # Rename the column\n",
    "        sheet_df = sheet_df.rename(columns={'Wormbase.ID': 'Wormbase_Id'})\n",
    "        cols = ['Wormbase_Id'] + [col for col in sheet_df.columns if col != 'Wormbase_Id']\n",
    "        sheet_df = sheet_df[cols]\n",
    "    output_file = dest_dir / sheet_map[sheet]\n",
    "    output_file.parent.mkdir(parents=True, exist_ok=True)\n",
    "    sheet_df.to_csv(output_file, index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46262006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table S5 Legend\n",
      "1 Cat1\n",
      "2 Cat2\n",
      "3 Cat3\n",
      "4 sams_up_genes\n",
      "5 sams_down_genes\n",
      "6 sams_up_CH_genes\n",
      "7 sams_down_CH_genes\n"
     ]
    }
   ],
   "source": [
    "# Process Supplemental_Table_5 Data of Wormcat Paper 1\n",
    "\n",
    "excel_file = source_data_path / \"wormcat_1\" / \"Supplemental_Table_5.xlsx\"\n",
    "dest_dir   = derived_data_path / \"wc1_sams\"\n",
    "\n",
    "sheet_map = {\n",
    "\t'Table S5 Legend'      :'wormcat1_results/legend.csv',\n",
    "\t'1 Cat1'               :'wormcat1_results/cat1.csv',\n",
    "\t'2 Cat2'               :'wormcat1_results/cat2.csv',\n",
    "\t'3 Cat3'               :'wormcat1_results/cat3.csv',\n",
    "\t'4 sams_up_genes'      :'sams/sams_up.csv',\n",
    "\t'5 sams_down_genes'    :'sams/sams_down.csv',\n",
    "\t'6 sams_up_CH_genes'   :'sams/sams_up_ch.csv',\n",
    "\t'7 sams_down_CH_genes' :'sams/sams_down_ch.csv'\n",
    "}\n",
    "\n",
    "input_excel = pd.ExcelFile(excel_file)\n",
    "for sheet in input_excel.sheet_names:\n",
    "    sheet_df = input_excel.parse(sheet)\n",
    "    print(sheet)\n",
    "    if 'Unnamed: 0'in sheet_df.columns:\n",
    "        sheet_df = sheet_df.drop(columns='Unnamed: 0')\n",
    "    if 'Wormbase.ID' in sheet_df.columns:\n",
    "        # Rename the column\n",
    "        sheet_df = sheet_df.rename(columns={'Wormbase.ID': 'Wormbase_Id'})\n",
    "        cols = ['Wormbase_Id'] + [col for col in sheet_df.columns if col != 'Wormbase_Id']\n",
    "        sheet_df = sheet_df[cols]\n",
    "    output_file = dest_dir / sheet_map[sheet]\n",
    "    output_file.parent.mkdir(parents=True, exist_ok=True)\n",
    "    sheet_df.to_csv(output_file, index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e01b3093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Legend\n",
      "1. Cat1\n",
      "2. Cat2\n",
      "3. Cat3\n",
      "4. all_detected_peptides_cat\n",
      "5. aging.change_cat\n",
      "6. Cytoplasm_cat\n"
     ]
    }
   ],
   "source": [
    "# Group Supplemental_Table_S8 Data into Subdirectories for Wormcat Batch Execution\n",
    "\n",
    "excel_file = source_data_path / \"wormcat_2\" / \"Table S8.xlsx\"\n",
    "dest_dir   = derived_data_path / \"wc2_peptides\"\n",
    "\n",
    "sheet_map = {\n",
    "\t'Legend'                       :'wormcat2_results/legend.csv',\n",
    "\t'1. Cat1'                      :'wormcat2_results/cat1.csv',\n",
    "\t'2. Cat2'                      :'wormcat2_results/cat2.csv',\n",
    "\t'3. Cat3'                      :'wormcat2_results/cat3.csv',\n",
    "\t'4. all_detected_peptides_cat' :'peptides/all_detected_peptides.csv',\n",
    "\t'5. aging.change_cat'          :'peptides/aging_change.csv',\n",
    "\t'6. Cytoplasm_cat'             :'peptides/cytoplasm.csv'\n",
    "}\n",
    "\n",
    "input_excel = pd.ExcelFile(excel_file)\n",
    "for sheet in input_excel.sheet_names:\n",
    "    sheet_df = input_excel.parse(sheet)\n",
    "    print(sheet)\n",
    "    if 'Unnamed: 0'in sheet_df.columns:\n",
    "        sheet_df = sheet_df.drop(columns='Unnamed: 0')\n",
    "    if 'Wormbase.ID' in sheet_df.columns:\n",
    "        # Rename the column\n",
    "        sheet_df = sheet_df.rename(columns={'Wormbase.ID': 'Wormbase_Id'})\n",
    "        cols = ['Wormbase_Id'] + [col for col in sheet_df.columns if col != 'Wormbase_Id']\n",
    "        sheet_df = sheet_df[cols]\n",
    "    output_file = dest_dir / sheet_map[sheet]\n",
    "    output_file.parent.mkdir(parents=True, exist_ok=True)\n",
    "    sheet_df.to_csv(output_file, index=False) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79955cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dan-dev-py312-r433",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
